{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\n\n# Load functionality to manipulate dataframes\nfrom pyspark.sql import functions as fn\nimport matplotlib.pyplot as plt\nfrom pyspark.sql.functions import col\n\n# Functionality for computing features\nfrom pyspark.ml import feature, regression, classification, Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import RFormula, Tokenizer, VectorAssembler, HashingTF, Word2Vec\n\nfrom pyspark.ml import clustering"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Replace with your values\n#\n# NOTE: Set the access to this notebook appropriately to protect the security of your keys.\n# Or you can delete this cell after you run the mount command below once successfully.\nACCESS_KEY = \"AKIAJNOOVI3SQZMPLJYQ\"\nSECRET_KEY = \"Ij0j+WlRKCuhBnqmCBXYLuOuC/R+gkYdyiNEeibq\"\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"advancedinfoanalytics\"\nMOUNT_NAME = \"mount1\"\n\n#dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#display(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["pac = \"dbfs:/mnt/mount1/acquisitions.csv\"\npad = \"dbfs:/mnt/mount1/additions.csv\"\npco = \"dbfs:/mnt/mount1/companies.csv\"\npin = \"dbfs:/mnt/mount1/investments.csv\"\npro = \"dbfs:/mnt/mount1/rounds.csv\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["dfacq = sqlContext.read.format(\"csv\").load(pac, delimiter = \",\", header = True)\ndfadd = sqlContext.read.format(\"csv\").load(pad, delimiter = \",\", header = True)\ndfcom = sqlContext.read.format(\"csv\").load(pco, delimiter = \",\", header = True)\ndinv = sqlContext.read.format(\"csv\").load(pin, delimiter = \",\", header = True)\ndfrou = sqlContext.read.format(\"csv\").load(pro, delimiter = \",\", header = True)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["<h2> Excel Spreadsheets with its columns </h2>\n<br/>\n\n<ul>\n  <li>Companies</li>\n  <ul>\n    <li>permalink</li>\n    <li>name</li>\n    <li>homepage_url</li>\n    <li>category_list</li>\n    <li>market</li>\n    <li>funding_total</li>\n    <li>status</li>\n    <li>country_code</li>\n    <li>state_code</li>\n    <li>region</li>\n    <li>city</li>\n    <li>funding_round</li>\n    <li>founded_at</li>\n    <li>founded_month</li>\n    <li>founded_quarter</li>\n    <li>founded_year</li>\n    <li>first_funding_at</li>\n    <li>last_funding_at</li>\n  </ul>\n  <li>Rounds</li>\n  <ul>\n    <li>company_permalink</li>\n    <li>company_name</li>\n    <li>company_category_list</li>\n    <li>company_market</li>\n    <li>company_country_code</li>\n    <li>company_state_code</li>\n    <li>company_region</li>\n    <li>company_city</li>\n    <li>funding_round_peramlink</li>\n    <li>funding_round_type</li>\n    <li>funding_round_code</li>\n    <li>fundet_at</li>\n    <li>funded_month</li>\n    <li>funded_quarter</li>\n    <li>funded_year</li>\n    <li>raised_amount_usd</li>\n  </ul>\n    <li>Investements</li>\n  <ul>\n    <li>company_permalink</li>\n    <li>company_name</li>\n    <li>company_category_list</li>\n    <li>company_market</li>\n    <li>company_country_code</li>\n    <li>company_state_code</li>\n    <li>company_region</li>\n    <li>company_city</li>\n    <li>investor_permalink</li>\n    <li>investor_name</li>\n    <li>investor_category_list</li>\n    <li>investor_market</li>\n    <li>investor_country_code</li>\n    <li>investor_region</li>\n    <li>investor_city</li>\n    <li>funding_round_permalink</li>\n    <li>funding_round_type</li>\n    <li>funding_round_code</li>\n    <li>funded_at</li>\n    <li>funded_month</li>\n    <li>funded_quarter</li>\n    <li>funded_year</li>\n    <li>rasied_amount_us</li>\n  </ul>\n  <li>Acquisitions</li>\n  <ul>\n    <li>company_permalink</li>\n    <li>company_name</li>\n    <li>company_category_list</li>\n    <li>company_market</li>\n    <li>company_country_code</li>\n    <li>company_state_code</li>\n    <li>company_region</li>\n    <li>company_city</li>\n    <li>acquirer_permalink</li>\n    <li>acquirer_name</li>\n    <li>acquirer_category_list</li>\n    <li>acquirer_market</li>\n    <li>acquirer_country_code</li>\n    <li>acquirer_state_code</li>\n    <li>acquirer_region</li>\n    <li>acquirer_city</li>\n    <li>acquired_at</li>\n    <li>acquired_month</li>\n    <li>acquired_quarter</li>\n    <li>acquired_year</li>\n    <li>price_amount</li>\n    <li>price_currency_code</li>\n  </ul>\n  <li>Additions</li>\n  <ul>\n    <li>content</li>\n    <li>month_str</li>\n    <li>quarter_str</li>\n    <li>year_str</li>\n    <li>value</li>\n  </ul>\n\n</ul>"],"metadata":{}},{"cell_type":"code","source":["display(\n  dfcom.select(\"status\").\\\n  groupby(col(\"status\")).\\\n  agg(fn.count(\"status\"))\n)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["dfcom.toPandas().isnull().sum()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["dfcom.filter(col(\"status\") == \"closed\").toPandas().isnull().sum()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["dfcom.filter(col(\"status\") == \"operating\").toPandas().isnull().sum()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["dfcom.filter(col(\"status\") == \"acquired\").toPandas().isnull().sum()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["display(dfcom)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["dfcom1 = dfcom.dropDuplicates(['name'])"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["dfcom1.count()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["ll = dfcom.select(\"category_list\").toPandas()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["ll.head()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["ll.shape"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["\nlist = []\nfor i in range(49438):  \n  yy = str(ll.category_list[i])\n  uu = yy.split(\"|\")\n  list.append(uu)\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["type(list[0])"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["li = pd.DataFrame({\"category\": list})"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["type(li)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["li.head()\n\n#TODO: get rid of the additional blank at beginning and end"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["li.dtypes"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["df_li = pd.DataFrame(li) "],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["df_li.head()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["type(df_li)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["df_categories = sqlContext.createDataFrame(df_li)\n\n#for Max Clustering\ndf_cat = sqlContext.createDataFrame(li)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["display(df_categories)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["display(df_cat)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["from pyspark.sql.functions import monotonically_increasing_id\n\n# This will return a new DF with all the columns + id\ndfcomid = dfcom.withColumn(\"id\", monotonically_increasing_id())\ndf_catid = df_cat.withColumn(\"id\", monotonically_increasing_id())"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["display(dfcomid.select('name', 'id'))\n\n#relation category to company via id"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["display(dfcategoriesid.select('1', 'id'))"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["display(df_catid)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"category\", outputCol=\"wordVec\")\nmodel = word2Vec.fit(df_catid)\ndfnew = model.transform(df_catid)\n\n#not in pipeline to check datatype\n#datatype is densevector\n#can be put in pipeline later on"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["display(dfnew)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["dfcatsample = dfnew.select(\"wordVec\").first().wordVec"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["type(dfcatsample)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["norm = feature.Normalizer(inputCol=\"wordVec\", outputCol=\"norm_wordVec\", p=2.0)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["kmeans = clustering.KMeans(k=5, featuresCol='norm_wordVec', predictionCol='kmeans_feat')"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["pipeline = Pipeline(stages=[norm, kmeans])"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["pipeline_model = pipeline.fit(dfnew)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["dfcatcluster = pipeline_model.transform(dfnew)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["display(dfcatcluster.select('id', 'category', 'wordVec', 'norm_wordVec', 'kmeans_feat').sort('kmeans_feat', ascending=False))"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["Non = [\"\", \"None\", \"\"]"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["display(dfcatcluster.select('id', 'category', 'wordVec', 'norm_wordVec', 'kmeans_feat').sort('category', ascending=False))\n\n#all nones are in one cluster\n#maybe we should exclude all none categories beforehand and categorize them as one cluster called no category"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":47}],"metadata":{"name":"startups","notebookId":3652805112490095},"nbformat":4,"nbformat_minor":0}
